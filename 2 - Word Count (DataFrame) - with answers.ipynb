{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count using DataFrames\n",
    "\n",
    "Spark DataFrames, a relatively new feature, provide a higher level interface similar to pandas DataFrames that abstract away much of the detail when using Spark. This exercise implements the previous word count with RDDs example, using DataFrames.\n",
    "\n",
    "We will cover:\n",
    "\n",
    "1. Creating DataFrames\n",
    "2. Counting with `.groupBy()` and `.count()`\n",
    "3. Finding unique words and a mean value\n",
    "4. Applying word count to a file\n",
    "\n",
    "Note that, for reference, you can look up the details of the relevant methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Creating a Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exercise, we will explore creating a DataFrame with `createDataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1a) Create a base DataFrame\n",
    "\n",
    "We'll start by generating a base DataFrame by using a pandas DataFrame and the `spark.createDataFrame` method.  Then we'll print out the type of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wordsPandasDF = pd.DataFrame({'word': ['cat', 'elephant', 'rat', 'rat', 'cat']})\n",
    "wordsDF = spark.createDataFrame(wordsPandasDF)\n",
    "\n",
    "# Print out the type of wordsRDD\n",
    "print(type(wordsDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word\n",
       "0       cat\n",
       "1  elephant\n",
       "2       rat\n",
       "3       rat\n",
       "4       cat"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back to a pandas DataFrame for pretty display\n",
    "wordsDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b) Pluralize and test\n",
    "\n",
    "Like in the previous exercise, let's create a function to pluralize a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n"
     ]
    }
   ],
   "source": [
    "# One way of completing the function\n",
    "def makePlural(word):\n",
    "    return word + 's'\n",
    "\n",
    "print(makePlural('cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Load in the testing code and check to see if your answer is correct\n",
    "# If incorrect it will report back '1 test failed' for each failed test\n",
    "# Make sure to rerun any cell you change before trying the test again\n",
    "from test_helper import Test\n",
    "# TEST Pluralize and test (1b)\n",
    "Test.assertEquals(makePlural('rat'), 'rats', 'incorrect result: makePlural does not add an s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1c) Apply `makePlural` to the base DataFrame\n",
    "\n",
    "In order to apply `makePlural` to a column from a Spark DataFrame, we must first create a Spark function. [pyspark.sql.functions](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions) provides a number of built in functions you can use, as well as [udf()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.udf), which allows you to create user defined functions.\n",
    "\n",
    "`udf()` takes as its arguments both the python function you want to use and a Spark type, which are defined in the [pyspark.sql.types](http://spark.apache.org/docs/2.0.0/api/python/pyspark.sql.html#module-pyspark.sql.types) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql import types\n",
    "\n",
    "# Create a Spark User Defined Function\n",
    "makePluralUDF = func.udf(makePlural, types.StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use `.select()` on a DataFrame to return a new DataFrame with the modified column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>makePlural(word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  makePlural(word)\n",
       "0             cats\n",
       "1        elephants\n",
       "2             rats\n",
       "3             rats\n",
       "4             cats"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a new DataFrame with a pluralized column\n",
    "pluralDF = wordsDF.select(makePluralUDF('word'))\n",
    "pluralDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Apply makePlural to the base RDD(1c)\n",
    "Test.assertEquals(list(pluralDF.toPandas()['makePlural(word)']),\n",
    "                  ['cats', 'elephants', 'rats', 'rats', 'cats'],\n",
    "                  'incorrect values for pluralRDD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1d) Make a UDF from a `lambda` function\n",
    "\n",
    "You can also create a UDF without first doing a `def` using a Python lambda function. Create the same UDF as above using a lambda function and apply it to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;lambda&gt;(word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  <lambda>(word)\n",
       "0           cats\n",
       "1      elephants\n",
       "2           rats\n",
       "3           rats\n",
       "4           cats"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Hint: Don't forget to pass in both the lambda function and the output type, e.g. types.StringType()\n",
    "makePluralLambdaUDF = func.udf(lambda s: s + 's', types.StringType())\n",
    "\n",
    "pluralLambdaDF = wordsDF.select(makePluralLambdaUDF('word'))\n",
    "pluralLambdaDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note as well that you can control the name of the column in the output DataFrame using `.alias()` on the UDF call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      plural\n",
       "0       cats\n",
       "1  elephants\n",
       "2       rats\n",
       "3       rats\n",
       "4       cats"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralLambdaDF = wordsDF.select(makePluralLambdaUDF('word').alias('plural'))\n",
    "pluralLambdaDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Pass a lambda function to map (1d)\n",
    "Test.assertEquals(list(pluralLambdaDF.toPandas()['plural']),\n",
    "                  ['cats', 'elephants', 'rats', 'rats', 'cats'],\n",
    "                  'incorrect values for pluralLambdaRDD (1d)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e) Length of each word\n",
    "\n",
    "Now construct a UDF to return the number of characters in each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plural</th>\n",
       "      <th>len(plural)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cats</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elephants</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rats</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rats</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      plural  len(plural)\n",
       "0       cats            4\n",
       "1  elephants            9\n",
       "2       rats            4\n",
       "3       rats            4\n",
       "4       cats            4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Hint: Don't forget to pass in both a Python function and the output type, e.g. types.StringType()\n",
    "lenUDF = func.udf(len, types.IntegerType())\n",
    "\n",
    "lengthsDF = pluralLambdaDF.select('*', lenUDF('plural'))\n",
    "lengthsDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Length of each word (1e)\n",
    "Test.assertEquals(list(lengthsDF.toPandas()['len(plural)']),\n",
    "                  [4, 9, 4, 4, 4],\n",
    "                  'incorrect values for pluralLengths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Counting with DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) `.groupBy()`\n",
    "\n",
    "When using DataFrames, we have a more abstract interface for performing complex operations on data. The `.groupBy()` method on a DataFrame returns a [GroupedData](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData) object, which supports a number of actions on grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GroupedData in module pyspark.sql.group object:\n",
      "\n",
      "class GroupedData(builtins.object)\n",
      " |  A set of methods for aggregations on a :class:`DataFrame`,\n",
      " |  created by :func:`DataFrame.groupBy`.\n",
      " |  \n",
      " |  .. note:: Experimental\n",
      " |  \n",
      " |  .. versionadded:: 1.3\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, jgd, sql_ctx)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  agg(self, *exprs)\n",
      " |      Compute aggregates and returns the result as a :class:`DataFrame`.\n",
      " |      \n",
      " |      The available aggregate functions are `avg`, `max`, `min`, `sum`, `count`.\n",
      " |      \n",
      " |      If ``exprs`` is a single :class:`dict` mapping from string to string, then the key\n",
      " |      is the column to perform aggregation on, and the value is the aggregate function.\n",
      " |      \n",
      " |      Alternatively, ``exprs`` can also be a list of aggregate :class:`Column` expressions.\n",
      " |      \n",
      " |      :param exprs: a dict mapping from column name (string) to aggregate functions (string),\n",
      " |          or a list of :class:`Column`.\n",
      " |      \n",
      " |      >>> gdf = df.groupBy(df.name)\n",
      " |      >>> sorted(gdf.agg({\"*\": \"count\"}).collect())\n",
      " |      [Row(name='Alice', count(1)=1), Row(name='Bob', count(1)=1)]\n",
      " |      \n",
      " |      >>> from pyspark.sql import functions as F\n",
      " |      >>> sorted(gdf.agg(F.min(df.age)).collect())\n",
      " |      [Row(name='Alice', min(age)=2), Row(name='Bob', min(age)=5)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  avg(self, *cols)\n",
      " |      Computes average values for each numeric columns for each group.\n",
      " |      \n",
      " |      :func:`mean` is an alias for :func:`avg`.\n",
      " |      \n",
      " |      :param cols: list of column names (string). Non-numeric columns are ignored.\n",
      " |      \n",
      " |      >>> df.groupBy().avg('age').collect()\n",
      " |      [Row(avg(age)=3.5)]\n",
      " |      >>> df3.groupBy().avg('age', 'height').collect()\n",
      " |      [Row(avg(age)=3.5, avg(height)=82.5)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  count(self)\n",
      " |      Counts the number of records for each group.\n",
      " |      \n",
      " |      >>> sorted(df.groupBy(df.age).count().collect())\n",
      " |      [Row(age=2, count=1), Row(age=5, count=1)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  max(self, *cols)\n",
      " |      Computes the max value for each numeric columns for each group.\n",
      " |      \n",
      " |      >>> df.groupBy().max('age').collect()\n",
      " |      [Row(max(age)=5)]\n",
      " |      >>> df3.groupBy().max('age', 'height').collect()\n",
      " |      [Row(max(age)=5, max(height)=85)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  mean(self, *cols)\n",
      " |      Computes average values for each numeric columns for each group.\n",
      " |      \n",
      " |      :func:`mean` is an alias for :func:`avg`.\n",
      " |      \n",
      " |      :param cols: list of column names (string). Non-numeric columns are ignored.\n",
      " |      \n",
      " |      >>> df.groupBy().mean('age').collect()\n",
      " |      [Row(avg(age)=3.5)]\n",
      " |      >>> df3.groupBy().mean('age', 'height').collect()\n",
      " |      [Row(avg(age)=3.5, avg(height)=82.5)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  min(self, *cols)\n",
      " |      Computes the min value for each numeric column for each group.\n",
      " |      \n",
      " |      :param cols: list of column names (string). Non-numeric columns are ignored.\n",
      " |      \n",
      " |      >>> df.groupBy().min('age').collect()\n",
      " |      [Row(min(age)=2)]\n",
      " |      >>> df3.groupBy().min('age', 'height').collect()\n",
      " |      [Row(min(age)=2, min(height)=80)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  pivot(self, pivot_col, values=None)\n",
      " |      Pivots a column of the current [[DataFrame]] and perform the specified aggregation.\n",
      " |      There are two versions of pivot function: one that requires the caller to specify the list\n",
      " |      of distinct values to pivot on, and one that does not. The latter is more concise but less\n",
      " |      efficient, because Spark needs to first compute the list of distinct values internally.\n",
      " |      \n",
      " |      :param pivot_col: Name of the column to pivot.\n",
      " |      :param values: List of values that will be translated to columns in the output DataFrame.\n",
      " |      \n",
      " |      # Compute the sum of earnings for each year by course with each course as a separate column\n",
      " |      \n",
      " |      >>> df4.groupBy(\"year\").pivot(\"course\", [\"dotNET\", \"Java\"]).sum(\"earnings\").collect()\n",
      " |      [Row(year=2012, dotNET=15000, Java=20000), Row(year=2013, dotNET=48000, Java=30000)]\n",
      " |      \n",
      " |      # Or without specifying column values (less efficient)\n",
      " |      \n",
      " |      >>> df4.groupBy(\"year\").pivot(\"course\").sum(\"earnings\").collect()\n",
      " |      [Row(year=2012, Java=20000, dotNET=15000), Row(year=2013, Java=30000, dotNET=48000)]\n",
      " |      \n",
      " |      .. versionadded:: 1.6\n",
      " |  \n",
      " |  sum(self, *cols)\n",
      " |      Compute the sum for each numeric columns for each group.\n",
      " |      \n",
      " |      :param cols: list of column names (string). Non-numeric columns are ignored.\n",
      " |      \n",
      " |      >>> df.groupBy().sum('age').collect()\n",
      " |      [Row(sum(age)=7)]\n",
      " |      >>> df3.groupBy().sum('age', 'height').collect()\n",
      " |      [Row(sum(age)=7, sum(height)=165)]\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedWords = wordsDF.groupBy('word')\n",
    "help(groupedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2b) `.groupBy().count()`\n",
    "\n",
    "In our case, where we have a single column of strings, only the `.count()` method really makes sense. This returns a new DataFrame with two columns, one with the words and one with the number of times they appeared in the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elephant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0       rat      2\n",
       "1       cat      2\n",
       "2  elephant      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts = wordsDF.groupBy('word').count()\n",
    "wordCounts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST word counts (2b)\n",
    "wordCountsPandasDF = wordCounts.toPandas()\n",
    "Test.assertEquals(sorted(zip(wordCountsPandasDF['word'], wordCountsPandasDF['count'])),\n",
    "                  [('cat', 2), ('elephant', 1), ('rat', 2)],\n",
    "                  'incorrect value for wordCountsCollected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Finding unique words and a mean value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3a) Unique words\n",
    "\n",
    "Calculate the number of unique words in `wordsDF`.  You can use other DataFrames that you have already created to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "numUniqueWords = wordCounts.count()\n",
    "print(numUniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Unique words (3a)\n",
    "Test.assertEquals(numUniqueWords, 3, 'incorrect count of numUniqueWords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) Mean word count\n",
    "\n",
    "Find the mean number of occurrences of each word in `wordCounts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "averageDF = wordCounts.select(func.avg('count'))\n",
    "\n",
    "# Collect DataFrame and get first value out of it\n",
    "average = np.array(averageDF.toPandas())[0, 0]\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Mean using reduce (3b)\n",
    "Test.assertEqualsTol(average, 1.6666667, 0.01, 'incorrect value of average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Apply word count to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will finish developing our word count application.  We'll have to build the `wordCount` function, deal with real world problems like capitalization and punctuation, load in our data source, and compute the word count on the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4a) `wordCount` function\n",
    "\n",
    "First, define a function for word counting.  This function should take in a DataFrame that is a list of words like `wordListDF` and return a DataFrame that has all of the words and their associated counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elephant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0       rat      2\n",
       "1       cat      2\n",
       "2  elephant      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def wordCount(wordListDF):\n",
    "    \"\"\"Creates a DataFrame with word counts from a DataFrame of words.\n",
    "\n",
    "    Args:\n",
    "        wordListDF (DataFrame): A DataFrame consisting of words.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A Spark DataFrame with word, count columns.\n",
    "    \"\"\"\n",
    "    return wordListDF.groupBy('word').count()\n",
    "\n",
    "wordCount(wordsDF).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST wordCount function (4a)\n",
    "wordCountsPandasDF = wordCount(wordsDF).toPandas()\n",
    "Test.assertEquals(sorted(zip(wordCountsPandasDF['word'], wordCountsPandasDF['count'])),\n",
    "                  [('cat', 2), ('elephant', 1), ('rat', 2)],\n",
    "                  'incorrect value for wordCountsCollected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4b) Capitalization and punctuation\n",
    "\n",
    "Here we defined the `removePunctuation` function from the previous exercise to preprocess text to cleaned words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi you\n",
      "no underscore\n",
      "the elephants 4 cats\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "import re\n",
    "\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9 ]', '', text.lower().strip())\n",
    "\n",
    "print(removePunctuation('Hi, you!'))\n",
    "print(removePunctuation(' No under_score!'))\n",
    "print(removePunctuation(\" The Elephant's 4 cats. \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Capitalization and punctuation (4b)\n",
    "Test.assertEquals(removePunctuation(\" The Elephant's 4 cats. \"),\n",
    "                  'the elephants 4 cats',\n",
    "                  'incorrect definition for removePunctuation function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4c) Load a text file\n",
    "\n",
    "For the next part, we will use the [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) from [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page). To convert a text file into a DataFrame, we use the `SparkContext.textFile()` method. We also apply the recently defined `removePunctuation()` function using a `map()` transformation to strip out the punctuation and change all text to lowercase.  Since the file is large we use `take(15)`, so that we only print 15 lines.\n",
    "\n",
    "Let's start by fetching the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-06-13 11:25:00--  https://s3-eu-west-1.amazonaws.com/asi-training-data/spark/shakespeare.txt\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 54.231.133.20\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|54.231.133.20|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5327978 (5.1M) [binary/octet-stream]\n",
      "Saving to: ‘shakespeare.txt’\n",
      "\n",
      "shakespeare.txt     100%[===================>]   5.08M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2017-06-13 11:25:00 (69.3 MB/s) - ‘shakespeare.txt’ saved [5327978/5327978]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm shakespeare.txt*\n",
    "!wget https://s3-eu-west-1.amazonaws.com/asi-training-data/spark/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by william shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from fairest creatures we desire increase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        line\n",
       "0                                       1609\n",
       "1                                           \n",
       "2                                the sonnets\n",
       "3                                           \n",
       "4                     by william shakespeare\n",
       "5                                           \n",
       "6                                           \n",
       "7                                           \n",
       "8                                          1\n",
       "9  from fairest creatures we desire increase"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"shakespeare.txt\"\n",
    "\n",
    "# Create a UDF for removePunctuation\n",
    "removePunctuationUDF = func.udf(removePunctuation, types.StringType())\n",
    "\n",
    "# Read the data from file and apply removePunctuation\n",
    "shakespeareDF = spark.read.text(filename).select(removePunctuationUDF('value').alias('line'))\n",
    "\n",
    "shakespeareDF.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4d) Words from lines \n",
    "\n",
    "Before we can use the `wordCount()` function, we have to address two issues with the format of the DataFrame:\n",
    "\n",
    "* The first issue is that  that we need to split each line by its spaces.\n",
    "* The second issue is we need to filter out empty lines.\n",
    " \n",
    "Apply a transformation that will split each element of the DataFrame by its spaces. For each element of the DataFra,e, you should apply Python's string [split()](https://docs.python.org/3/library/stdtypes.html#str.split) function. You might think that applying a UDF to a column directly is the way to do this, but think about what the result of the `split()` function will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sonnets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "0     1609\n",
       "1         \n",
       "2      the\n",
       "3  sonnets\n",
       "4         "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeareWordsDF = (shakespeareDF\n",
    "                      .select(func.explode(func.split('line', ' ')).alias('word')))\n",
    "\n",
    "shakespeareWordsDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Words from lines (4d)\n",
    "# This test allows for leading spaces to be removed either before or after\n",
    "# punctuation is removed.\n",
    "Test.assertTrue(shakespeareWordsDF.count() in [927631, 928908],\n",
    "                'incorrect number of words in shakespeareWordsDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4e) Remove empty elements\n",
    "\n",
    "The next step is to filter out the empty elements.  Remove all entries where the word is `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882996\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "shakeWordsDF = shakespeareWordsDF.filter(func.length('word') > 0)\n",
    "shakeWordCount = shakeWordsDF.count()\n",
    "print(shakeWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Remove empty elements (4e)\n",
    "Test.assertEquals(shakeWordCount, 882996, 'incorrect value for shakeWordCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4f) Count the words\n",
    "\n",
    "We now have an RDD that is only words.  Next, let's apply the `wordCount()` function to produce a list of word counts. We can view the top 15 words by using the `takeOrdered()` action; however, since the elements of the RDD are pairs, we need a custom sort function that sorts using the value part of the pair.\n",
    "\n",
    "You'll notice that many of the words are common English words. These are called stopwords. In a later lab, we will see how to eliminate them from the results.\n",
    "\n",
    "Use the `wordCount()` function and `takeOrdered()` to obtain the fifteen most common words and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 27361\n",
      "and: 26028\n",
      "i: 20681\n",
      "to: 19150\n",
      "of: 17463\n",
      "a: 14593\n",
      "you: 13615\n",
      "my: 12481\n",
      "in: 10956\n",
      "that: 10890\n",
      "is: 9134\n",
      "not: 8497\n",
      "with: 7771\n",
      "me: 7769\n",
      "it: 7678\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "top15WordsAndCounts = (wordCount(shakeWordsDF)\n",
    "                       .sort('count', ascending=False)\n",
    "                       .head(15))\n",
    "\n",
    "for row in top15WordsAndCounts:\n",
    "    print('{0}: {1}'.format(*row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Count the words (4f)\n",
    "Test.assertEquals(top15WordsAndCounts,\n",
    "                  [(u'the', 27361), (u'and', 26028), (u'i', 20681), (u'to', 19150), (u'of', 17463),\n",
    "                   (u'a', 14593), (u'you', 13615), (u'my', 12481), (u'in', 10956), (u'that', 10890),\n",
    "                   (u'is', 9134), (u'not', 8497), (u'with', 7771), (u'me', 7769), (u'it', 7678)],\n",
    "                  'incorrect value for top15WordsAndCounts')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
